{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description of the project.\n",
    "\n",
    "As an analyst at a big online store, together with the marketing department, we look at the list of hypotheses that may help boost revenue. We look at the results of A/B hypothesis testing. Our goal is to analyze the results and decide whether it is reasonable to continue testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used in the first part of the project:\n",
    "### /datasets/hypotheses_us.csv \n",
    "\n",
    "\n",
    "Hypotheses — brief descriptions of the hypotheses\n",
    "\n",
    "Reach — user reach, on a scale of one to ten\n",
    "\n",
    "Impact — impact on users, on a scale of one to ten\n",
    "\n",
    "Confidence — confidence in the hypothesis, on a scale of one to ten\n",
    "\n",
    "Effort — the resources required to test a hypothesis, on a scale of one to ten. The higher the Effort value, the more resource-intensive the test.\n",
    "\n",
    "\n",
    "## Data used in the second part of the project:\n",
    "### /datasets/orders_us.csv \n",
    "\n",
    "\n",
    "\n",
    "transactionId — order identifier\n",
    "\n",
    "visitorId — identifier of the user who placed the order\n",
    "\n",
    "date — of the order\n",
    "\n",
    "revenue — from the order\n",
    "\n",
    "group — the A/B test group that the user belongs to\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### /datasets/visits_us.csv \n",
    "\n",
    "date — date\n",
    "\n",
    "group — A/B test group\n",
    "\n",
    "visits — the number of visits on the date specified in the A/B test group specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from scipy import stats as st\n",
    "from numpy import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import datetime as dt\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = pd.read_csv('/datasets/hypotheses_us.csv', sep=';')\n",
    "orders = pd.read_csv('/datasets/orders_us.csv')\n",
    "visits = pd.read_csv('/datasets/visits_us.csv')\n",
    "\n",
    "display(hypotheses.info())\n",
    "\n",
    "display(hypotheses.head(10))\n",
    "display(orders.info())\n",
    "display(visits.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below I am removing the orders that got mistakingly assigned to both groups. It's a pretty high percentage of orders; however, we have to remove them, since there is no way to know, which group is correct and it can seriously skew the graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl = orders.groupby('visitorId').agg({'group':'nunique'})\n",
    "dupl_ = dupl[dupl['group']>1].reset_index()\n",
    "orders = orders.loc[~orders['visitorId'].isin(dupl_['visitorId'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1. Prioritizing Hypotheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ICE\n",
    "hypotheses['ICE'] = hypotheses['Impact'] * hypotheses['Confidence'] /hypotheses['Effort']\n",
    "\n",
    "print(hypotheses[['Hypothesis','ICE']].sort_values(by='ICE', ascending=False))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RICE\n",
    "hypotheses['RICE'] = hypotheses['Reach'] * hypotheses['Impact'] * hypotheses['Confidence'] /hypotheses['Effort']\n",
    "print(hypotheses[['Hypothesis','RICE']].sort_values(by='RICE', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2. A/B Test Analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph cumulative revenue by group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders['date'] = pd.to_datetime(orders['date'], format=\"%Y-%m-%d %H:%M\")\n",
    "visits['date'] = pd.to_datetime(visits['date'], format=\"%Y-%m-%d %H:%M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datesGroups = orders[['date','group']].drop_duplicates() \n",
    "ordersAggregated = datesGroups.apply(\n",
    "    lambda x: orders[np.logical_and(orders['date'] <= x['date'], orders['group'] == x['group'])].agg({\n",
    "'date' : 'max',\n",
    "'group' : 'max',\n",
    "'transactionId' : pd.Series.nunique,\n",
    "'visitorId' : pd.Series.nunique,\n",
    "'revenue' : 'sum'}), axis=1).sort_values(by=['date','group']) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visitorsAggregated = datesGroups.apply(lambda x: visits[np.logical_and(visits['date'] <= x['date'], visits['group'] == x['group'])].agg({'date' : 'max', 'group' : 'max', 'visits' : 'sum'}), axis=1).sort_values(by=['date','group']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeData = ordersAggregated.merge(visitorsAggregated, left_on=['date', 'group'], right_on=['date', 'group'])\n",
    "cumulativeData.columns = ['date', 'group', 'orders', 'buyers', 'revenue', 'visitors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeRevenueA = cumulativeData[cumulativeData['group']=='A'][['date','revenue', 'orders']]\n",
    "cumulativeRevenueB = cumulativeData[cumulativeData['group']=='B'][['date','revenue', 'orders']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(cumulativeRevenueA['date'], cumulativeRevenueA['revenue'], label='A')\n",
    "plt.plot(cumulativeRevenueB['date'], cumulativeRevenueB['revenue'], label='B')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Cumulative Revenue')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this graph that values for group B ar slightly lower in the beginning of the month, but very quickly become mych higher with very high growth between 2019-08-17 and 21. We can assume there was huge sudden growth between these days and after that revenue kept steadily climbing up with group B a clear leader."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph cumulative average order size by group.\n",
    "Cumulative graphs (by day) for average purchase size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(cumulativeRevenueA['date'], cumulativeRevenueA['revenue']/cumulativeRevenueA['orders'], label='A')\n",
    "plt.plot(cumulativeRevenueB['date'], cumulativeRevenueB['revenue']/cumulativeRevenueB['orders'], label='B')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Cumulative average order size by group')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('average order size')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see, again, that between the days 2019-08-17 and 21 the order size for group B spiked; however, then we see a downward trend. It is partigularly interesting since, as we know from the previous graph, the revenue for group B kept steadily increasing. Later we will see if anything changes after we remove abnormalities. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph the relative difference in cumulative average order size for group B\n",
    "compared with group A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gathering the data into one DataFrame\n",
    "mergedCumulativeRevenue = cumulativeRevenueA.merge(cumulativeRevenueB, left_on='date', right_on='date', how='left', suffixes=['A', 'B'])\n",
    "\n",
    "# plotting a relative difference graph for the average purchase sizes\n",
    "plt.plot(mergedCumulativeRevenue['date'], (mergedCumulativeRevenue['revenueB']/mergedCumulativeRevenue['ordersB'])/(mergedCumulativeRevenue['revenueA']/mergedCumulativeRevenue['ordersA'])-1)\n",
    "\n",
    "# adding the X axis\n",
    "plt.axhline(y=0, color='black', linestyle='--') \n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Difference in cumulative average order size')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Relative difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see severe fluctuations, serious and sudden changes. It may be connected to abnormally big orders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate each group's conversion rate as the ratio of orders to the\n",
    "number of visits for each day. Plot the daily conversion rates of the two\n",
    "groups and describe the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulativeData['conversion'] = cumulativeData['orders']/cumulativeData['visitors']\n",
    "\n",
    "# selecting data on group A \n",
    "cumulativeDataA = cumulativeData[cumulativeData['group']=='A']\n",
    "\n",
    "# selecting data on group B\n",
    "cumulativeDataB = cumulativeData[cumulativeData['group']=='B']\n",
    "\n",
    "# plotting the graphs\n",
    "plt.plot(cumulativeDataA['date'], cumulativeDataA['conversion'], label='A')\n",
    "plt.plot(cumulativeDataB['date'], cumulativeDataB['conversion'], label='B')\n",
    "plt.title('Daily conversion rates')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Conversion rate')\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that in the beginning there were fluctuations and group A started out in better condition than group B. However, after somewhere between 08.05 and 08.09 group B conversion became higher and the trend stabilised: conversion for group B is relatively stable with small spikes, but conversion for group A steadily declines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting relative difference in conversion rates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedCumulativeConversions = cumulativeDataA[['date','conversion']].merge(cumulativeDataB[['date','conversion']], left_on='date', right_on='date', how='left', suffixes=['A', 'B'])\n",
    "\n",
    "plt.plot(mergedCumulativeConversions['date'], mergedCumulativeConversions['conversionB']/mergedCumulativeConversions['conversionA']-1, label=\"Relative gain in conversion in group B as opposed to group A\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=90)\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "plt.axhline(y=0.2, color='grey', linestyle='--')\n",
    "plt.title('Relative difference in conversion rates')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Difference')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conversion ratio is not yet stable; however, we can see on this graph that B started low, but quickly went up, and is still fluctuating, alsthough not as severely as in the beginning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a scatter chart of the number of orders per user. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersByUsers = orders.drop(['group', 'revenue', 'date'], axis=1).groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsers.columns = ['visitorId','orders']\n",
    "\n",
    "\n",
    "# the range of numbers from 0 to the number of observations in ordersByUsers\n",
    "x_values = pd.Series(range(0,len(ordersByUsers)))\n",
    "plt.scatter(x_values, ordersByUsers['orders']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the vast majority of users make one order, there is a bunch of users with two orders and a minority of users have 3. 3 may be an anomaly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the 95th and 99th percentiles for the number of orders per user.\n",
    "Define the point at which a data point becomes an anomaly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentiles = np.percentile(ordersByUsers['orders'], [95, 99])\n",
    "print(percentiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5% of users made 2 orders, and only one % made 3 orders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scatter plot I'd say the abnormal plot is 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram and scatter chart of order prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(orders['revenue']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = pd.Series(range(0,len(orders['revenue'])))\n",
    "plt.scatter(x_values, orders['revenue']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vast majority of prices is below 2500$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "95th and 99th percentiles of order prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.percentile(orders['revenue'], [95, 99])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 5% of order prices are  more than 415$, and only one more than 830$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd say the abnormal plot is 830.3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the statistical significance of the difference in conversion between the\n",
    "groups using the raw data.\n",
    "\n",
    "For each statistical test below I will be using alpha balue of 0.5. I will specify hypotheses as it goes.\n",
    "For the test below the H0 is that there's not a statistically significant difference in conversion between the groups. H1 is that there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersByUsersA = orders[orders['group']=='A'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersA.columns = ['visitorId', 'orders']\n",
    "\n",
    "ordersByUsersB = orders[orders['group']=='B'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersB.columns = ['visitorIdd', 'orders']\n",
    "\n",
    "#pd.Series(0, index=np.arange(data['visitorsPerDateA'].sum() - len(ordersByUsersA['orders'])), name='orders')\n",
    "    \n",
    "[ordersByUsersA['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='A']['visits'].sum() - len(ordersByUsersA['orders'])), name='orders')] \n",
    "\n",
    "sampleA = pd.concat([ordersByUsersA['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='A']['visits'].sum() - len(ordersByUsersA['orders'])), name='orders')],axis=0)\n",
    "\n",
    "sampleB = pd.concat([ordersByUsersB['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='B']['visits'].sum() - len(ordersByUsersB['orders'])), name='orders')],axis=0)  \n",
    "    \n",
    "    \n",
    "ordersByUsersA = orders[orders['group']=='A'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersA.columns = ['visitorId', 'orders']\n",
    "\n",
    "ordersByUsersB = orders[orders['group']=='B'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersB.columns = ['visitorId', 'orders']\n",
    "\n",
    "sampleA = pd.concat([ordersByUsersA['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='A']['visits'].sum() - len(ordersByUsersA['orders'])), name='orders')],axis=0)\n",
    "\n",
    "sampleB = pd.concat([ordersByUsersB['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='B']['visits'].sum() - len(ordersByUsersB['orders'])), name='orders')],axis=0)\n",
    "\n",
    "#relative difference in conversion between the groups: \n",
    "print(\"{0:.5f}\".format(st.mannwhitneyu(sampleA, sampleB)[1]))\n",
    "print(\"{0:.3f}\".format(sampleB.mean()/sampleA.mean()-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is much lower than 0.05 and the relative conversion gain for group B compared to group A is 16%. Thus we have to reject the H0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the statistical significance of the difference in average order size between the groups using the raw data. The H0 is that there is no significant difference in average order size between the groups. H1 is that there is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:.3f}\".format(st.mannwhitneyu(orders[orders['group']=='A']['revenue'], orders[orders['group']=='B']['revenue'])[1]))\n",
    "print(\"{0:.3f}\".format(orders[orders['group']=='B']['revenue'].mean()/orders[orders['group']=='A']['revenue'].mean()-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is higher than 0.05, so we can't regect the H0: the hypothesis that there is no serious statistical difference betwen group's average order sizes. Now we will repeat the test after removing anomalies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing anomalies from our data.\n",
    "95th and 99th percentiles for average order size are 435.54 and 900.904 and 95th and 99th % of orders per user are two and four orders. I decided to define anomalies as more than 2 orders that cost more than 1000 $. Now I will remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordersByUsersA = orders[orders['group']=='A'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersA.columns = ['visitorId', 'orders']\n",
    "\n",
    "ordersByUsersB = orders[orders['group']=='B'].groupby('visitorId', as_index=False).agg({'transactionId' : pd.Series.nunique})\n",
    "ordersByUsersB.columns = ['visitorId', 'orders']\n",
    "\n",
    "usersWithManyOrders = pd.concat([ordersByUsersA[ordersByUsersA['orders'] > 2]['visitorId'], ordersByUsersB[ordersByUsersB['orders'] > 2]['visitorId']], axis = 0)\n",
    "usersWithExpensiveOrders = orders[orders['revenue'] > 1000]['visitorId']\n",
    "abnormalUsers = pd.concat([usersWithManyOrders, usersWithExpensiveOrders], axis = 0).drop_duplicates().sort_values(ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I calculate the difference in conversion after removing the anomalies using the filtered data. H0 is that there's not a statistically significant difference in conversion between the groups. H1 is that there is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleAFiltered = pd.concat([ordersByUsersA[np.logical_not(ordersByUsersA['visitorId'].isin(abnormalUsers))]['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='A']['visits'].sum() - len(ordersByUsersA['orders'])),name='orders')],axis=0)\n",
    "\n",
    "sampleBFiltered = pd.concat([ordersByUsersB[np.logical_not(ordersByUsersB['visitorId'].isin(abnormalUsers))]['orders'],pd.Series(0, index=np.arange(visits[visits['group']=='B']['visits'].sum() - len(ordersByUsersB['orders'])),name='orders')],axis=0) \n",
    "\n",
    "print(\"{0:.5f}\".format(st.mannwhitneyu(sampleAFiltered, sampleBFiltered)[1]))\n",
    "print(\"{0:.3f}\".format(sampleBFiltered.mean()/sampleAFiltered.mean()-1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value is lower than 0.05, so we have to reject H0 hypotheses that there is no statistically important difference in conversion for two groups. The statistical difference between groups is about 18%, which is very high. Group B is in the lead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the anomalies and calculating the statistical significance for the difference in average order size using the filtered data. The H0 is that there is no significant difference in average order size between the groups. H1 is that there is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"{0:.3f}\".format(st.mannwhitneyu(\n",
    "    orders[np.logical_and(\n",
    "        orders['group']=='A',\n",
    "        np.logical_not(orders['visitorId'].isin(abnormalUsers)))]['revenue'],\n",
    "    orders[np.logical_and(\n",
    "        orders['group']=='B',\n",
    "        np.logical_not(orders['visitorId'].isin(abnormalUsers)))]['revenue'])[1]))\n",
    "\n",
    "print(\"{0:.3f}\".format(\n",
    "    orders[np.logical_and(orders['group']=='B',np.logical_not(orders['visitorId'].isin(abnormalUsers)))]['revenue'].mean()/\n",
    "    orders[np.logical_and(\n",
    "        orders['group']=='A',\n",
    "        np.logical_not(orders['visitorId'].isin(abnormalUsers)))]['revenue'].mean() - 1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P-value is higher than 0.05,so we can not reject the H0. The difference in order size is small,about 3.5%. In group A it is actually higher, but it doesn't change the difference in revenue. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a statistically significant difference in conversion between the groups, according to both the raw and the filtered data.\n",
    "The raw data didn't show a statistically significant difference between the groups in terms of average purchase size even after the anomalies were removed.\n",
    "The graph of the difference in conversion between the groups shows that group B's results are better than those of group A.\n",
    "The graph of the difference in average purchase size shows fluctuations; however, there was no statistical significance to that difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the facts listed above, I think we should conclude the test: group B has done better overal when it came to revenue and conversion and there was no serious statistical difference between order sizes, even after the removal of anomalies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
